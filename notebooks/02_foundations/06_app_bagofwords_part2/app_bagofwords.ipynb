{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\is}{\\mathrel{\\mathop:=}}$\n",
    "$\\newcommand{\\range}{\\mathop{ran}}$\n",
    "$\\newcommand{\\setof}[1]{\\left \\{ #1 \\right \\}}$\n",
    "$\\newcommand{\\card}[1]{\\left | #1 \\right |}$\n",
    "$\\newcommand{\\tuple}[1]{\\left \\langle #1 \\right \\rangle}$\n",
    "$\\newcommand{\\emptytuple}{\\left \\langle \\right \\rangle}$\n",
    "$\\newcommand{\\tuplecat}{\\cdot}$\n",
    "$\\newcommand{\\emptystring}{\\varepsilon}$\n",
    "$\\newcommand{\\String}[1]{\\mathit{#1}}$\n",
    "$\\newcommand{\\LeftEdgeSymbol}{\\rtimes}$\n",
    "$\\newcommand{\\RightEdgeSymbol}{\\ltimes}$\n",
    "$\\newcommand{\\LeftEdge}{\\LeftEdgeSymbol}$\n",
    "$\\newcommand{\\RightEdge}{\\RightEdgeSymbol}$\n",
    "$\\newcommand{\\mult}{\\times}$\n",
    "$\\newcommand{\\multisum}{\\uplus}$\n",
    "$\\newcommand{\\multimult}{\\otimes}$\n",
    "$\\newcommand{\\freqsymbol}{\\mathrm{freq}}$\n",
    "$\\newcommand{\\freq}[1]{\\freqsymbol(#1)}$\n",
    "\n",
    "# Bag of Words Revisited\n",
    "\n",
    "By now you are familiar with a rudimentary version of the bag-of-words model.\n",
    "I say rudimentary because, to be frank, we haven't looked at the actual bag-of-words model yet.\n",
    "Our version of the bag-of-words model maps texts (formalized as strings) to sets.\n",
    "But this isn't what is commonly understood as a bag-of-words model, most people would call it a \"set-of-words\" model.\n",
    "A bag-of-words isn't supposed to jut list the word types that occur in a text, it lists the word types and the respective number of tokens.\n",
    "So the true bag-of-words model maps strings to multisets.\n",
    "\n",
    "## Keeping Track of Counts\n",
    "\n",
    "As a reminder, here is our original definition of the bag-of-words model, now with a more appropriate name:\n",
    "\n",
    "<div class=definition>\n",
    "Let $\\Sigma$ be some fixed finite set of words.\n",
    "A *set-of-words* model is a function $s: \\Sigma^+ \\rightarrow \\wp(\\Sigma)$ such that for all $t \\in \\Sigma^+$\n",
    "\n",
    "$$\n",
    "s(t)\n",
    "\\is\n",
    "\\begin{cases}\n",
    "    \\setof{t} & \\text{if } t \\in \\Sigma\\\\\n",
    "    s(u) \\cup s(v) & \\text{if } t = u \\tuplecat v, \\text{ where } u, v \\in \\Sigma^+\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "Only a minor change is needed for a proper bag-of-words model that extracts counts for all word types.\n",
    "\n",
    "<div class=definition>\n",
    "Let $\\Sigma$ be some fixed finite set of words.\n",
    "A *bag-of-words* model is a function $b: \\Sigma^+ \\rightarrow \\Sigma \\times \\mathbb{N}$ such that for all $t \\in \\Sigma^+$\n",
    "\n",
    "$$\n",
    "b(t)\n",
    "\\is\n",
    "\\begin{cases}\n",
    "    \\setof{t: 1} & \\text{if } t \\in \\Sigma\\\\\n",
    "    b(u) + b(v) & \\text{if } t = u \\tuplecat v, \\text{ where } u, v \\in \\Sigma^+\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "<div class=example>\n",
    "The set-of-words model converts the mini-text *Only John could like John* (modulo capitalization) to the set $\\setof{\\text{only}, \\text{john}, \\text{could}, \\text{like}}$.\n",
    "The sentence *If police police police police police, then police police police police police* it converts to $\\setof{\\text{if}, \\text{police}, \\text{then}}$.\n",
    "\n",
    "The bag-of-words model gives different results.\n",
    "The first sentence is mapped to the multiset $\\setof{\\text{only}: 1, \\text{john}: 2, \\text{could}: 1, \\text{like}: 1}$.\n",
    "The second one yields $\\setof{\\text{if}: 1, \\text{police}: 10, \\text{then}: 1}$.\n",
    "</div>\n",
    "\n",
    "Note that we can still modify the model to remove stop words or use $n$-grams instead of unigrams.\n",
    "The function $\\mathrm{del}_S$, which deletes all members of $S$ from the text, does not need to be altered at all, and the change in the $n$-gram variant $b_n$ of $b$ is almost unnoticeable.\n",
    "\n",
    "<div class=definition>\n",
    "An *$n$-gram set-of-word model* is a function $s_n: \\Sigma^* \\rightarrow \\wp(\\Sigma^n)$ such that $t \\mapsto \\setof{ g \\mid t = u \\tuplecat g \\tuplecat v, \\text{ where } g \\in \\Sigma^n \\text{ and } u,v \\in \\Sigma^*}$.\n",
    "</div>\n",
    "\n",
    "<div class=definition>\n",
    "An *$n$-gram bag-of-word model* is a function $b_n: \\Sigma^* \\rightarrow \\Sigma^n \\times \\mathbb{N}$ such that $t \\mapsto \\setof{ g \\mid t = u \\tuplecat g \\tuplecat v, \\text{ where } g \\in \\Sigma^n \\text{ and } u,v \\in \\Sigma^*}_M$.\n",
    "</div>\n",
    "\n",
    "<div class=example>\n",
    "Consider once more the sentence *Only John could like John*.\n",
    "A bigram set-of-words model would map this to $\\setof{\\text{only john}, \\text{john could}, \\text{could like}, \\text{like john}}$.\n",
    "The bigram bag-of-words model instead yields $\\setof{\\text{only john}: 1, \\text{john could}: 1, \\text{could like}: 1, \\text{like john}: 1}$.\n",
    "How does this result come about according to the definition?\n",
    "\n",
    "For every bigram in the set-of-words, we have to calculate its count.\n",
    "Its count is equivalent the number of string pairs $\\tuple{u,v}$ such that we can wrap $u$ and $v$ around the bigram to obtain the original text.\n",
    "For each bigram there is only one working fitting pair $\\tuple{u,v}$ in this text.\n",
    "\n",
    "$$\\begin{array}{rrl}\n",
    "    u                      & \\text{bigram}     &  v\\\\\n",
    "    \\emptystring           & \\text{only john}  &  \\text{could like john}\\\\\n",
    "    \\text{only}            & \\text{john could} &  \\text{like john}\\\\\n",
    "    \\text{only john}       & \\text{could like} &  \\text{john}\\\\\n",
    "    \\text{only john could} & \\text{like John}  &  \\emptystring\\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Now let's look at *If police police police police police, then police police police police police*.\n",
    "The bigram set-of-words model returns $\\setof{\\text{if police}, \\text{police police}, \\text{police then}, \\text{then police}}$.\n",
    "And with a bigram bag-of-words model we get the multiste $\\setof{\\text{if police}: 1, \\text{police police}: 8, \\text{police then}: 1, \\text{then police}: 1}$.\n",
    "Again we have to look at the possible $\\tuple{u,v}$ pairs for each bigram to determine its count.\n",
    "To avoid clutter, we write $\\text{police}^n$ for $n$ instance of *police* in a row.\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "    u                                        & \\text{bigram}        & v\\\\\n",
    "    \\emptystring                             & \\text{if police}     & \\text{police}^4 \\text{ then police}^5\\\\\n",
    "    \\text{if}                                & \\text{police police} & \\text{police}^3 \\text{ then police}^5\\\\\n",
    "    \\text{if police}                         &                      & \\text{police}^2 \\text{ then police}^5\\\\\n",
    "    \\text{if police}^2                       &                      & \\text{police} \\text{ then police}^5\\\\\n",
    "    \\text{if police}^3                       &                      & \\text{then police}^5\\\\\n",
    "    \\text{if police}^5 \\text{ then}          &                      & \\text{police}^3\\\\\n",
    "    \\text{if police}^5 \\text{ then police}   &                      & \\text{police}^2\\\\\n",
    "    \\text{if police}^5 \\text{ then police}^2 &                      & \\text{police}\\\\\n",
    "    \\text{if police}^5 \\text{ then police}^3 &                      & \\emptystring\\\\\n",
    "    \\text{if police}^4                       & \\text{police then}   & \\text{police}^5\\\\\n",
    "    \\text{if police}^5                       & \\text{then police}   & \\text{police}^4\\\\\n",
    "\\end{array}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set for only john could like john: {('like', 'john'), ('only', 'john'), ('john', 'could'), ('could', 'like')}\n",
      "Multiset for only john could like john: Counter({('like', 'john'): 1, ('only', 'john'): 1, ('john', 'could'): 1, ('could', 'like'): 1})\n",
      "\n",
      "Set for if police police police police police then police police police police police: {('then', 'police'), ('if', 'police'), ('police', 'police'), ('police', 'then')}\n",
      "Multiset for if police police police police police then police police police police police: Counter({('police', 'police'): 8, ('then', 'police'): 1, ('if', 'police'): 1, ('police', 'then'): 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def ngram_list(text, n):\n",
    "    return zip(*[text[pos:] for pos in range(n)])\n",
    "\n",
    "def ngram_set(text, n):\n",
    "    return set(ngram_list(text, n))\n",
    "\n",
    "def ngram_multiset(text, n):\n",
    "    return Counter(ngram_list(text, n))\n",
    "\n",
    "sentence1 = [\"only\", \"john\", \"could\", \"like\", \"john\"]\n",
    "sentence2 = [\"if\", \"police\", \"police\", \"police\", \"police\", \"police\",\n",
    "             \"then\", \"police\", \"police\", \"police\", \"police\", \"police\"]\n",
    "\n",
    "print(\"Set for {}: {}\".format(\" \".join(sentence1), ngram_set(sentence1, 2)))\n",
    "print(\"Multiset for {}: {}\".format(\" \".join(sentence1), ngram_multiset(sentence1, 2)))\n",
    "print()\n",
    "print(\"Set for {}: {}\".format(\" \".join(sentence2), ngram_set(sentence2, 2)))\n",
    "print(\"Multiset for {}: {}\".format(\" \".join(sentence2), ngram_multiset(sentence2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts for Frequencies and Probabilities\n",
    "\n",
    "One major advantage the proper bag-of-words model has over the set-of-words model is that the counts provide direct information about frequency, which can be used in various ways.\n",
    "Given a multiset $S_M$, the frequency of some $s \\in S_M$ is the count of $s$ divided by the total of all counts.\n",
    "Since the latter is identical to the cardinality of $S_M$, we can calculate frequency with the general formula $\\freq{s} \\is \\frac{S_M(s)}{\\card{S_M}}$.\n",
    "We can extend the function to multisets such that $\\freq{S_M} \\is \\setof{ \\tuple{s, \\freq{s}} \\mid s \\in S_M}$.\n",
    "Since $\\tuple{s, \\freq{s}}$ is a little cumbersome to right inside sets, we sometimes write $s: \\freq{s}$ instead.\n",
    "However, do not let the notation fool you - $\\freq{S_M}$ is not a multiset because the frequencies range from $0$ to $1$ and thus aren't limited to natural numbers.\n",
    "\n",
    "<div class=example>\n",
    "Let's go back to the multiset \n",
    "$S_M \\is \\setof{\\text{if police}: 1, \\text{police police}: 8, \\text{police then}: 1, \\text{then police}: 1}$.\n",
    "The cardinality of this set is $\\sum_{s \\in S_M} S_M(s) = 1 + 8 + 1 + 1 = 11$.\n",
    "Hence $\\freq{S_M} =  \\setof{\\text{if police}: \\frac{1}{11}, \\text{police police}: \\frac{8}{11}, \\text{police then}: \\frac{1}{11}, \\text{then police}: \\frac{1}{11}}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('if',): 0.08333333333333333,\n",
      " ('police',): 0.8333333333333334,\n",
      " ('then',): 0.08333333333333333}\n",
      "{('if', 'police'): 0.09090909090909091,\n",
      " ('police', 'police'): 0.7272727272727273,\n",
      " ('police', 'then'): 0.09090909090909091,\n",
      " ('then', 'police'): 0.09090909090909091}\n",
      "{('if', 'police', 'police'): 0.1,\n",
      " ('police', 'police', 'police'): 0.6,\n",
      " ('police', 'police', 'then'): 0.1,\n",
      " ('police', 'then', 'police'): 0.1,\n",
      " ('then', 'police', 'police'): 0.1}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "unigrams = ngram_multiset(sentence2, 1)\n",
    "bigrams = ngram_multiset(sentence2, 2)\n",
    "trigrams = ngram_multiset(sentence2, 3)\n",
    "\n",
    "for ngrams in [unigrams, bigrams, trigrams]:\n",
    "    total = sum(ngrams.values())\n",
    "    pprint({key: val/total for key, val in ngrams.items()})\n",
    "\n",
    "for ngrams in {1: unigrams, 2: bigrams, 3: trigrams}.items():\n",
    "    label = ngrams[0]\n",
    "    count = ngrams[1]\n",
    "    # plt.bar(list(count.keys()), count.values(), color='b')\n",
    "    # plt.txt(str(label)+\"-gram\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts and frequency information can be used in various ways.\n",
    "For example, we might measure the relevance of a text for a search query based on how much of the text consists of the words in the search query.\n",
    "In this case, it is particularly important to remove all stop words.\n",
    "\n",
    "<div class=example>\n",
    "The sentence *Only John thinks John thinks John likes John* corresponds to the multiset\n",
    "$S_M \\is \\setof{\\text{only}: 1, \\text{john}: 4, \\text{thinks}: 2, \\text{likes}: 1}$.\n",
    "With frequencies instead of counts this is\n",
    "$S_M \\is \\setof{\\text{only}: 0.125, \\text{john}: 0.5, \\text{thinks}: 0.25, \\text{likes}: 0.5}$.\n",
    "So the relevance score to the query *john* would be .5\n",
    "\n",
    "*I like John* blabla bla\n",
    "</div>\n",
    "\n",
    "\n",
    "## Handling Data Sparsity with Skip $n$-Grams"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
