# Are Natural Languages Infinite?

There are three reasons why the existence of multiple infinite cardinalities matters for language:

1. Only recursively enumerable sets can be computed with perfect precision.
1. Linguists have discussed for a long time whether natural languages are infinite, but seldom are they explicit about the degree of infinity ($\aleph_0$, $\aleph_1$, ...).
1. Linguistic arguments that language is infinite are rarely worked out at a formal level, and that hides an important confound in those arguments.

## Lexicon

Linguists use the term *lexicon* to refer a speaker's knowledge of the words in their language.
Formally, a lexicon can be regarded as a set of triples, where each triple encodes the pronunciation of a word, its meaning, and its grammatical properties like part of speech.
We will not put too fine a point on this technical definition and just treat a lexicon as a set $\Lex$ of words.

It is reasonable to assume that if $\Lex$ is infinite, then so is the language that uses $\Lex$.
A word is useful only if it can be used in a sentence, and presumably every word stored in a lexicon must be useful in this way --- otherwise, why would it be stored there?
But if there are infinitely many words that are useful in this sense, then there must be infinitely many sentences.
We can make this logic more explicit by a total injective function from words in the lexicon to sentences of the language.
For the sake of simplicity we will use English here, but the same kind of function can be construed for Spanish, German, Russian, Mandarin Chinese, Turkish, Navajo, or Inuktitut.
The important thing is that the function must be total and injective.
In that case, every element in the domain gets mapped to a different element of the co-domain, and thus the cardinality of the co-domain must be at least as large as the cardinality of the domain.

**Words** | **Sentences**
--:       | :--
apple     | "apple" is an English word.
banana    | "banana" is an English word.
orange    | "orange" is an English word.
...       | ...

The function computing this mapping is $f: \Lex \rightarrow \Sigma^+$ such that $w \mapsto w \tuplecat \tuple{\text{is}, \text{a}, \text{word}, \text{of}, \text{English}}$.
Mathematically, we can be certain that $f$ is total and injective, so if $\Lex$ is infinite for English, then English is infinite in the sense that there are infinitely many strings of English words that are well-formed sentences.

But this argument is predicated on $\Lex$ being infinite, and that is not a straight-forward argument to make.
The Oxford English Dictionary contains a remarkable number of English words, but only finitely many.
If we ask a speaker to tell us all the words they know, they can only tell us so many before they die, and even if all of mankind were dedicated to the task of listing words of English only finitely many could be uttered before mankind expires due to the heat death of the universe.
So there can never be any direct evidence.

This is why many linguists make a distinction between *competence* and *performance*.
The latter describes the knowledge a speaker has of their native language, the latter what they are able to do with it given other external constraints such as limited working memory, fatigue, the need to eat and sleep, or the finite nature of the universe.
The fact that only finitely many words can be uttered before the end of the universe is a performance limitation, it does not tell us anything about competence.
So if we take a competence view, are there good reasons to believe that the lexicon of a language is infinite?
And if so, what degree of infinity are we talking about?

## There is no Longest Word

Consider for a moment the set of natural numbers and how a child figures out that this set is infinite.
The essential insight is that there is no such thing as a largest number.
No matter what natural number $n$ one picks, there is always an $n+1$ that is distinct from all numbers before it.
So there simply cannot be finitely many natural numbers as that would entail that there is some $n$ for which no $n+1$ exists.
Let us refer to $n+1$ as the successor of $n$, computed by the successor function $S: \mathbb{N} \rightarrow \mathbb{N}_+$ with $n \mapsto n+1$.
The infinity of $\mathbb{N}$ follows from the fact that $\mathbb{N}$ is *closed* under successor.

\begin{definition}
    A set $A$ is *closed* under an $n$-ary function $f$ iff it holds for all $a_1, \ldots, a_n \in A$ that $f(a_1, \ldots, a_n) \in A$.
    For every set $B$, the *closure of $B$ under $f$* is the smallest $A \supseteq B$ such that $A$ is closed under $f$.
\end{definition}

\begin{example}
    The natural numbers are closed under addition and multiplication because the sum or product of two natural numbers is always a natural number.
    The same is true for the even natural numbers.
    The set of odd natural numbers, on the other hand, is closed under multiplication but not addition: $1 \in \mathbb{N}_o$, but $1 + 1 = 2 \notin \mathbb{N}_o$.
    The closure of the odd natural numbers under addition is the set of all natural numbers.
\end{example}

\begin{example}
    That a set $A$ is closed under a specific function does not necessarily entail that the set is infinite.
    For example, let $A \is \setof{0,1}$.
    This set is closed under multiplication because $0 \mult 0 = 0 \mult 1 = 1 \mult 0 = 1$ and $1 \mult 1 = 1$.
\end{example}

The same argument can be applied to languages: if $\Lex$ is not infinite, then there must be such a thing as a longest word.
But this cannot be the case because the lexicon is closed under certain operations that keep producing longer and longer words.

There's many ways word length can be measured, but counting letters will be sufficient here (although it is a horrible measure from a linguistic perspective --- *through* has more letters than *banana*, but fewer sounds).
If there is a longest English word $w$, then there has to be some natural number $n$ such that the length of $w$ is $n$.
Some English words can be very long, for example the infamous *supercalifragilisticexpialidocious*, which contains 34 letters.
But there is a longer word: *great great great great great grandfather*, which has 36 letters.
And *great great great great great great grandfather* has 41 letters.
Quite generally, *great$^n$ grandfather* has $11 + 5n$ letters.
Unless there is some bound on the number of instances of *great* before *grandfather*, we can freely iterate *great* to show that there is no longest word of English.

You might object that this isn't a word because it contains spaces, but that is not a linguistic definition of what a word is.
Spoken language has no concept of spaces, and we can't rely on an arbitrary spelling convention to define crucial linguistic notions.
For all intents and purposes, *great$^n$ grandfather* behaves like any other noun, and nouns are words.

1. We can replace other nouns by *great$^n$ grandfather*:  
   *My annoying neighbor smells* $\Rightarrow$ *My great$^n$ grandfather smells*
1. As other words, we cannot split it in the middle:  
   *My bro funny ther smells* $\Rightarrow$ *My great$^n$ funny grandfather smells*

So there is good reason to assume that *great grandfather*, *great great grandfather*, and so on, are words of English, and the competence perspective allows us to assume that for each $n \in \mathbb{N}$, *great$^n$ grandfather* is part of an English speaker's mental lexicon.
We thus have a bijecion between the *great grandfather* construction and $\mathbb{N}$.

**Word**                | $\mathbb{N}$
--:                     | :--
grandfather             | 0
great grandfather       | 1
great great grandfather | 2
great great grandfather | 3
...                     | ...

So there is an infinite subset of $\Lex$ with cardinality $\aleph_0$.
Alternatively, we could also say that $\Lex$ properly subsumes the closure of *grandfather* under *great*-prefixation: $w \mapsto \text{great}\ w$.
Either way it follows that $\card{\Lex} \geq \aleph_0$.
But it is also clear that $\card{\Lex} \not> \aleph_0$ because we can define a bijection between $\Lex$ and natural numbers: order all members of $\Lex$ by their length, and words of the same length are ordered in alphabetical order.
So $\card{\Lex} = \aleph_0$, which means that the lexicon of a natural language is recursively enumerable.

Since each member of $\Lex$ can occur in at least one sentence of English, the set of English sentences is also infinite.
Using the same strategy of ordering sentences by length and alphabetical order, we also get a bijection between sentences of English and natural numbers.
So when English is viewed as a set of sentences, it also has cardinality $\aleph_0$.

## Many Roads Lead to Rome

There are many other ways of showing that English is infinite given the competence-performance distinction.
One argument comes from **compounding**, where existing words are combined into new words.
This is just a more general instance of the *great$^n$ grandfather* pattern.
For example, the word *supervisor* can be compounded with itself to yield *supervisor supervisor*, i.e. somebody who supervises a supervisor.
But then of course there can be a *supervisor supervisor supervisor*, and a *supervisor supervisor supervisor supervisor*, and so on.

More importantly, one can show that English would be infinite even if the set of words is taken to be finite.
This holds because many parts of sentences allow for **free iteration**.

1.  Iteration with adverbs
    1. John is tired.
    1. John is very tired.
    1. John is very very tired.
    1. John is very very very tired.
1.  Iteration with adjectives
    1. John saw a man.
    1. John saw an old man.
    1. John saw an old, old man.
    1. John saw an old, old, old man.
1.  Iteration with relative clauses
    1. John saw the man.
    1. John saw the man that the other John also saw.
    1. John saw the man that the other John also saw that yet another John also saw.
    1. John saw the man that the other John also saw that yet another John also saw that yet another John also saw.

It is also possible to embed material within other material, seemingly without bound (although the sentences quickly become hard to understand).

1.  Embedding of sentential complements
    1. I know that Sue left.
    1. You know that I know that Sue left.
    1. I know that you know that I know that you know that Sue left.
1.  Right embedding of relative clauses
    1. The cat chased the mouse.
    1. The cat chased the cat that chased the mouse.
    1. The cat chased the cat that chased the cat that chased the mouse.
1.  Center embedding of relative clauses
    1. The cat chased the mouse.
    1. The cat that the cat chased chased the mouse.
    1. The cat that the cat that the cat chased chased chased the mouse.

All these examples are sufficient to show that English is recursively enumerable given the competence-performance distinction.

Somewhat more surprisingly, one can even show that English contains every possible (non-empty) string over $\Lex$:

1. Every sequence of English words is a possible band name, so the set of possible band names is $\Lex^+$.
1. Every band name can be given as an answer to the question *What is your favorite band?*.
1. Each answer to this question is a sentence of English.

As usual, we can define a bijection between $\Lex^+$ and $\mathbb{N}$, which shows that English is recursively enumerable.


## Why Does Infinity Matter?

It is important to keep in mind that the arguments above all hinge on the competence-performance distinction.
As such they are circular: we set out to ask whether languages are infinite, and then we made the assumption that mechanisms like compounding, iteration, and embedding can be applied without bound.
But this can be the case only if languages are infinite, so we are implicitly assuming what we are trying to prove.
From a mathematical perspective this is faulty reasoning, but from a linguistic perspective it is nonetheless insightful.

The crucial issue isn't whether languages are actually infinite.
Rather, we obtained two very useful results, one negative and one positive:

1. If languages are infinite, they do not have cardinality $\aleph_1$ or greater than that.
   So they are at most recursively enumerable, which is an important bound for computation.
1. Languages can easily be viewed as infinite sets.
   So even if a natural language $L$ is actually finite, we can always factorize it into an infinite set $I$ and a finite set $F$ such that $I \cap F = L$.

The second result tells us that generalizing languages from finite samples to infinite patterns can be done in a very natural fashion that is methodologically innocent.
Yet another way of saying this is that natural languages are so large that one may just as well view them as infinite.
Where the finite nature of languages matter, it can always be added on top of the infinite characterization.
